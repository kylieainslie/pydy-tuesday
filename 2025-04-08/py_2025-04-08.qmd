---
title: "Pydy Tuesday 2025-04-08"
format: html
jupyter: python3
---

# Data Source
<img src="visits.png" style="float: right; width: 100px; height: auto; margin-right: 100px;" />

**Data Source:** This week we're exploring state-level results for medicare.gov "timely and effective care" measurements. As of 2025-04-06, the data is available at the [Centers for Medicare and Medicaid Services (CMS) website](https://data.cms.gov/provider-data/dataset/apyc-v239).

*Data provided by:* Tracy Teal (@tracykteal).
*Additional links:*
    - [a visualization by Kayla Zhu and Christina Kostandi at the Visual Capitalist](https://www.visualcapitalist.com/mapped-emergency-room-visit-times-by-state/) 

### Background
Emergency room wait times vary significantly across the United States depending on factors such as hospital resources, patient volume, and staffing levels, with some states facing delays that can stretch for more than three hours.

- Is there a connection between state populations and wait times?
- Which conditions have the longest wait times? The shortest?


## Set up
```{python}
# import required libraries
import os
import PyDyTuesday
import pandas as pd
import requests
from tqdm import tqdm 
from great_tables import GT

# set working directory (only for line by line coding)
# comment out when rendering!
#os.getcwd()
#os.chdir(os.getcwd() + '/2025-04-08')
```

## Download data
We can download the data using the `PyDyTuesday` library and specifying the date. This will load several files:

- `care_state.csv`: data file.
- `visits.png`: image file.
- `meta.yaml`: meta data file with information about the data files and the curator.

The data dictionary is located [here](https://github.com/rfordatascience/tidytuesday/blob/main/data/2025/2025-04-08/readme.md#data-dictionary)

```{python}
# Download files from the week, which you can then read in locally
PyDyTuesday.get_date('2025-04-08')

df = pd.read_csv("care_state.csv", encoding='latin-1')
```

```{python}
#| echo: false

(
    GT(df.head())
    .tab_header(title="Visit Times per State")
    .fmt_date(columns=["start_date", "end_date"])
    .fmt_number(columns=["score"])
)
```

## Data Exploration
Since there are numerous conditions reported in the data, let's restrict our analysis to those conditions for the Emergency Department (`condition = 'Emergency Department'`). We'll also restrict our analysis to measures of average time in the emergency department before being seen, which is `measure_id` code starting with `"OP_18b"`.
```{python}
df_ed = df[df['condition'] == 'Emergency Department']
df_ed_op = df_ed[df_ed['measure_id'].str.startswith('OP_18b')]
df_ed_op.head()
```

To get a feel for the data, let's plot the a histogram of the average time spent in the emergency department before being seen.
```{python}
import matplotlib.pyplot as plt

plt.hist(df_ed_op['score'], bins=30, color='skyblue', edgecolor='black')
plt.xlabel('Average time (in minutes) spent in ED before being sent home.')
plt.ylabel('Frequency')
#plt.title('Histogram of Your Column')
plt.show()
```

From the histogram, we see that the time spent in the ED has a long tail, suggesting that it might be gamma distributed. Let's check this by fitting a gamma distribution to the data and looking at a Q-Q plot.

```{python}
import scipy.stats as stats
import seaborn as sns
import numpy as np

data = df_ed_op['score'].dropna()

# Fit a gamma distribution
shape, loc, scale = stats.gamma.fit(data)

stats.probplot(data, dist="gamma", sparams=(shape, loc, scale), plot=plt)
plt.title('Q-Q Plot: Gamma Distribution')
plt.show()

# Perform the Kolmogorov-Smirnov (K-S) test
ks_stat, ks_p_value = stats.kstest(data, 'gamma', args=(shape, loc, scale))

# Print the result
print(f'K-S Statistic: {ks_stat}, p-value: {ks_p_value}')
```

Based on these diagnostics, the Gamma distribution is not a good fit for our data. Let's try a couple of other distributions to see if we get a better fit. We'll fit the following distributions to our data:

- Normal
- Log-normal
- Weibull
- Exponential

We'll test each distribution's fit with our data using the Kolmogorov-Smirnov (K-S) test as we did above. A small K-S statistic indicates that the data and the fitted distribution are similar, whereas, a large K-S statistic indicates that there is a large discrepancy between the data and the fitted distribution.

```{python}
# 1. Normal Distribution
params_normal = stats.norm.fit(data)

# 2. Log-Normal Distribution
params_lognormal = stats.lognorm.fit(data, floc=0) 

# 3. Weibull Distribution
params_weibull = stats.weibull_min.fit(data, floc=0) 

# 4. Exponential Distribution
params_exponential = stats.expon.fit(data, floc=0)  

# Perform KS test for each distribution
ks_stat_normal, p_value_normal = stats.kstest(data, 'norm', args=params_normal)
ks_stat_lognormal, p_value_lognormal = stats.kstest(data, 'lognorm', args=params_lognormal)
ks_stat_weibull, p_value_weibull = stats.kstest(data, 'weibull_min', args=params_weibull)
ks_stat_exponential, p_value_exponential = stats.kstest(data, 'expon', args=params_exponential)

# Print KS statistics and p-values
print(f"Normal KS Statistic: {ks_stat_normal}, p-value: {p_value_normal}")
print(f"Log-Normal KS Statistic: {ks_stat_lognormal}, p-value: {p_value_lognormal}")
print(f"Weibull KS Statistic: {ks_stat_weibull}, p-value: {p_value_weibull}")
print(f"Exponential KS Statistic: {ks_stat_exponential}, p-value: {p_value_exponential}")
```

From these results, it looks like the log-normal distribution is the best fit to our data.

```{python}
#| echo: false
plt.clf()

plt.hist(data, bins=30, color='skyblue', edgecolor='black', density=True, alpha=0.6)
x = np.linspace(min(data), max(data), 1000)
pdf_lognormal = stats.lognorm.pdf(x, *params_lognormal)
plt.plot(x, pdf_lognormal, 'g-', label="Log-Normal Fit")
plt.xlabel('Average time (in minutes) spent in ED before being sent home.')
plt.ylabel('Density')
plt.legend()
plt.show()
```

# Model fitting
Now that we've determine the distribution that best fits our outcome variable of interest, we can use an appropriate model, here a generalised linear model with log link, to try to understand what variables in our dataset are associated with ED wait times.

```{python}
import statsmodels.api as sm
from statsmodels.formula.api import glm

df_fit = df_ed_op.dropna(subset=['score'])

model = glm('score ~ state', data=df_fit, family=sm.families.Gaussian(link=sm.families.links.log())).fit()
#print(model.summary())
```